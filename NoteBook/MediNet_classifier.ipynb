{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21668168",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Input, Conv2D, DepthwiseConv2D, BatchNormalization,\n",
    "                                     Activation, Add, Dropout, GlobalAveragePooling2D,\n",
    "                                     Dense, Multiply, Reshape)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def efficient_channel_attention(x, ratio=8):\n",
    "    ch = K.int_shape(x)[-1]\n",
    "    if ch is None:\n",
    "        return x\n",
    "    se = GlobalAveragePooling2D()(x)\n",
    "    se = Dense(max(1, ch // ratio), activation='relu', use_bias=True)(se)\n",
    "    se = Dense(ch, activation='sigmoid', use_bias=True)(se)\n",
    "    se = Reshape((1, 1, ch))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "def inverted_residual_block(x_in, filters_out, strides=1, expansion_factor=4, use_attention=True, dropout_rate=0.0):\n",
    "    shortcut = x_in\n",
    "    filters_in = K.int_shape(x_in)[-1]\n",
    "    if expansion_factor > 1:\n",
    "        x = Conv2D(filters_in * expansion_factor, 1, padding='same', use_bias=False, kernel_initializer='he_normal')(x_in)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu6')(x)\n",
    "    else:\n",
    "        x = x_in\n",
    "    x = DepthwiseConv2D(3, strides=strides, padding='same', use_bias=False, depthwise_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu6')(x)\n",
    "    if use_attention and filters_out >= 64:\n",
    "        x = efficient_channel_attention(x, ratio=8)\n",
    "    x = Conv2D(filters_out, 1, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    if strides == 1 and filters_in == filters_out:\n",
    "        x = Add()([shortcut, x])\n",
    "    return x\n",
    "\n",
    "def create_MediNet_XG(input_shape, num_classes, width_multiplier=0.5):\n",
    "    def make_divisible(v, divisor=8):\n",
    "        new_v = max(divisor, int(v + divisor / 2) // divisor * divisor)\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    filters = make_divisible(16 * width_multiplier)\n",
    "    x = Conv2D(filters, 3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu6')(x)\n",
    "\n",
    "    stage_configs = [\n",
    "        (24, 2, 2, False),\n",
    "        (32, 3, 2, False),\n",
    "        (64, 4, 2, True),\n",
    "        (96, 6, 1, True),\n",
    "    ]\n",
    "    for f, expansion, stride, use_attn in stage_configs:\n",
    "        f = make_divisible(f * width_multiplier)\n",
    "        x = inverted_residual_block(x, f, strides=stride, expansion_factor=expansion, use_attention=use_attn, dropout_rate=0.1)\n",
    "        x = inverted_residual_block(x, f, strides=1, expansion_factor=expansion, use_attention=use_attn, dropout_rate=0.0)\n",
    "\n",
    "    final_filters = make_divisible(320 * width_multiplier)\n",
    "    x = Conv2D(final_filters, 1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu6')(x)\n",
    "    emb = GlobalAveragePooling2D(name=\"embedding\")(x)\n",
    "    x = Dropout(0.2)(emb)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"MediNet_XG\")\n",
    "\n",
    "def get_callbacks(model_name):\n",
    "    return [\n",
    "        ModelCheckpoint(f\"{OUTPUT_DIR}/best_loss_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=0),\n",
    "        ModelCheckpoint(f\"{OUTPUT_DIR}/best_acc_{model_name}.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=0),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=0),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-6, verbose=0),\n",
    "    ]\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true, y_prob = [], []\n",
    "    for x, y in dataset:\n",
    "        y_true.append(y.numpy())\n",
    "        y_prob.append(model.predict(x, verbose=0))\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_prob = np.vstack(y_prob)\n",
    "    y_true_idx = np.argmax(y_true, axis=1)\n",
    "    y_pred_idx = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    loss, acc = model.evaluate(dataset, verbose=0)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(y_true_idx, y_pred_idx, average=\"macro\", zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc_ovr = float(roc_auc_score(y_true, y_prob, multi_class=\"ovr\"))\n",
    "    except Exception:\n",
    "        auc_ovr = float(\"nan\")\n",
    "\n",
    "    report_txt = classification_report(y_true_idx, y_pred_idx, target_names=class_names, zero_division=0)\n",
    "    report_dict = classification_report(y_true_idx, y_pred_idx, target_names=class_names, zero_division=0, output_dict=True)\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx)\n",
    "\n",
    "    return {\n",
    "        \"loss\": float(loss),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision_macro\": float(pr),\n",
    "        \"recall_macro\": float(rc),\n",
    "        \"f1_macro\": float(f1),\n",
    "        \"auc_ovr\": float(auc_ovr),\n",
    "        \"report_txt\": report_txt,\n",
    "        \"report_dict\": report_dict,\n",
    "        \"cm\": cm\n",
    "    }\n",
    "\n",
    "input_shape = (img_size, img_size, 3)\n",
    "medinet_xg = create_MediNet_XG(input_shape, num_classes, width_multiplier=0.5)\n",
    "medinet_xg.compile(optimizer=SGD(learning_rate=0.01, momentum=0.8, nesterov=True),\n",
    "                   loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_medinet = medinet_xg.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=get_callbacks(\"MediNet_XG\"),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "medinet_xg.save(f\"{OUTPUT_DIR}/MediNet_XG_final.h5\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.plot(history_medinet.history[\"accuracy\"]); plt.plot(history_medinet.history[\"val_accuracy\"])\n",
    "plt.title(\"MediNet_XG Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend([\"train\",\"val\"])\n",
    "plt.subplot(1,2,2); plt.plot(history_medinet.history[\"loss\"]); plt.plot(history_medinet.history[\"val_loss\"])\n",
    "plt.title(\"MediNet_XG Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend([\"train\",\"val\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/curves_MediNet_XG.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "eval_medinet = evaluate_model(medinet_xg, test_dataset)\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/classification_report_MediNet_XG.txt\", \"w\") as f:\n",
    "    f.write(eval_medinet[\"report_txt\"])\n",
    "with open(f\"{OUTPUT_DIR}/classification_report_MediNet_XG.json\", \"w\") as f:\n",
    "    json.dump(eval_medinet[\"report_dict\"], f, indent=2)\n",
    "with open(f\"{OUTPUT_DIR}/metrics_MediNet_XG.json\", \"w\") as f:\n",
    "    json.dump({k: eval_medinet[k] for k in [\"loss\",\"accuracy\",\"precision_macro\",\"recall_macro\",\"f1_macro\",\"auc_ovr\"]}, f, indent=2)\n",
    "\n",
    "cm = eval_medinet[\"cm\"]\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/confusion_matrix_MediNet_XG.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "eff_path = f\"{OUTPUT_DIR}/MediNet_XG_final.h5\"\n",
    "params = int(medinet_xg.count_params())\n",
    "size_kb = os.path.getsize(eff_path) / 1024\n",
    "\n",
    "start = time.time()\n",
    "n = 0\n",
    "for x, _ in test_dataset.take(5):\n",
    "    _ = medinet_xg.predict(x, verbose=0)\n",
    "    n += x.shape[0]\n",
    "ms_per_img = ((time.time() - start) / max(1, n)) * 1000\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/efficiency_MediNet_XG.json\", \"w\") as f:\n",
    "    json.dump({\"params\": params, \"size_kb\": float(size_kb), \"ms_per_image\": float(ms_per_img)}, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
